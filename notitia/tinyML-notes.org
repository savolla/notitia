#+TITLE: Tiny Ml Notes
#+AUTHOR: savolla
#+HUGO_BASE_DIR: ~/txt/blog/
#+HUGO_SECTION: en/posts

:PROPERTIES:
:EXPORT_FILE_NAME: tinyml-book-notes
:EXPORT_TITLE: TinyML Kitap Özeti
:HUGO_BASE_DIR: ~/txt/blog/
:HUGO_SECTION: en/posts
:EXPORT_AUTHOR: savolla
:END:

* TinyML Kitap Notları

[[file:./images/screenshot-97.png]]

* Bölüm 1

- Gömülü sistemlerde (Cortex-M4) yapay zeka uygulaması yapmak mümkün!

- çoğu gömülü sistem yazılımı, =new= ya da =malloc()= kullanmaktan kaçınır.

- ~fact~ Gömülü sistemlerde *heap* kullanmak kötü bir fikirdir

- Dynamic memory allocation'ın en büyük zararı, zaman içinde RAM'i bozmasıdır. bkz: *Fragmentation*

- Tensorflow'un MCU'lar için çıkardığı ürün *Tensorflow Lite*'dır

* Bölüm 2

- Bu kitapta şu *Gömülü Yapay Zeka* projeleri yer almaktadır;

  1. Speech recognition (microphone)
  2. hareket algılama (hareket sensörü)
  3. Detect PPL (camera sensor)

- yukarıda bahsi geçen projeleri siz kendiniz modifiye edebilirsiniz. örnek olarak Speech recognition ile yapılan insan konuşması algılama projesini modifiye edip köpek havlamasını tespit edebilen bir cihaz yapılabilir. Bu sayede insan yerine köpek tespiti yapan küçük cihazlar yapabilirsiniz

- Yapay zekayı eğitme kısmını tamamen [[https://colab.research.google.com/notebooks/intro.ipynb#scrollTo=OwuxHmxllTwN][Google Colab]] üstünde gerçekleştireceğiz. Yani süper özelliklere sahip bir bilgisayara ihtiyacımız kalmadı

- ~fact~ Low power bir MCU'da (1 mW gibi) gidip de 10 mW tüketen bir kamera sensörü kullanırsanız, kullandığınız low power MCU'nun bir anlamı kalmaz. Proje "low power" olmaktan çıkar yani

* Bölüm 3

- Yapay Zeka ilk bakışta zor görünen bir alan olarak karşımıza çıksa ve ileri matematik, tonlarca makale ve uzman olmak için yıllar geçmesi gerekiyor gibi görünse de aslında işin uygulama kısmı bir kaç tool'dan ibarettir. Göz korkutacak bir şey yok. Yapay zeka ile ilgili bir kaç konsept öğrendikten sonra, projelerde kullanabilirsiniz

- Bu kitapta yapay zeka uygulamalarını küçük cihazlarda nasıl kullanacağımızı anlatıyoruz. Teori ile işimiz yok.

- Kullanışlı yapay zeka uygulamalarını yapmaya başlamak için bütün teoriyi bilmeye gerek yok. Bu bölümde gerekli miktarda bir giriş yapılacak

- yapay zeka uygulaması, diğer kod ile yazdığımız uygulamalardan farklıdır. kod yazmak yerine, hali hazırda var olan bir yapay zeka algoritmasına topladığımız verileri gireriz ve yapay zeka algoritması, bu verileri işleyip finalde bize bir model çıkartır. Biz bu modele yeni bir veri girdiğimizde de model bize bir tahmin üretir

- yapay zeka uygulamalarında kod kalitesinden çok _veri kalitesi_ önemlidir

- örnek olarak bir fabrika düşünelim, üretim yapan bir makine var ancak bu makine bazen bozuluyor ve tamiri masraflı. bu makinenin sıcaklığını, titreşimi gibi verileri bir süre aldığımızı var sayalım. yeterli miktarda veriye ulaştıktan sonra bir yapay zeka algoritmasını bu verilerle eğitip, makina bozulmaya yakın onu kapatan bir yapay zeka uygulaması yapabiliriz

- *training* : yapay zeka kendisine sunulan verileri işleyip öğrenmesine denir. Sonuçta bir model oluşur

- *model* : yapay zeka algoritmasının ürettiği çıktı. Bu çıktı aslında bir programdır ve yeni veriler geldiğinde bir tahmin üretir

- *inference*: modele yeni veriler verdiğimizde, modelin yeni bir tahmin yapma sürecine denir

- bir yapay zeka uygulamasında izlenecek adımlar;

  1. Hedef Belirleme (uygulama ne yapacak)
  2. Veri Toplama
  3. Nöral Network Oluşturma
  4. *Train* işlemi
  5. Convert the mode ~TODO~
  6. *Inference* işlemi (yeni girdi verip çıktı al)
  7. modeli test et ve sorun gider

- MCU'lar genelde az hafıza ve işlem gücüne sahip olduklarından dolayı, model oluştururken, cihazın bu özellikleri göz önünde bulundurulmalıdır. Yani çok büyük bir nöral networkü, küçük bir MCU'ya koymak olanaksızdır.

- Nöral networkün boyutunu etkileyen faktörler;

  1. Nöron sayısı
  2. Nöronlar arasındaki bağlantı sayısı

- yapay zeka modeline girdi olarak bir tensör verilir. çıktı olarak da bir tensör alınır

** Tensor

- bu, tek boyutlu bir tensor'dür. Bunun diğer bir ismi *vector*'dür. boyutu ise $(5,)$ şeklinde gösterilir

  #+begin_src python
[1 3 4 5 6]
  #+end_src

- bu ise 2D bir tensördür. başka bi isimle *matrix* denir. boyutu $(3, 3)$'dür

  #+begin_src python
[[1 3 4]
 [5 6 0]
 [2 2 0]]
  #+end_src

- matrix'den daha çok boyutlu tensörlere de kısaca *tensor* dneir. Aşağıdaki matris $(2,3,3)$ boyutlarına sahiptir çünkü _2 tane 3'e 3'lük matris barındırıyor_

  #+begin_src python
[
    [[1 3 4]
     [5 6 0]
     [2 2 0]]

    [[1 3 4]
     [5 6 0]
     [2 2 0]]
]
  #+end_src
** Sliding Windowing Technique

- Devamlı olarak gelen veriden bir anlam çıkartmak zordur. Çünkü verinin tamamına ihtiyacımız vardır. Örneğin bir ortalama alacaksak verinin tamamen elde edilene kadar beklenilmesi gerekir.

 [[file:./images/screenshot-94.png]]

- Peki ya veri daha akarken bir sonuç çıkartmak istersek? işte o zaman veriye kendi belirlediğimiz genişlikte bir pencere açarız.

 [[file:./images/screenshot-93.png]]

- Yukarıdaki her yıldız verisinin gelmesi 10 saniye sürüyor. Biz de her 10 saniyede bir verinin fotoğrafını çekip o verilerin ortalamasını alıp, yapay zeka modelimize okutup çıktı elde ederiz.

 [[file:./images/screenshot-95.png]]

- Yapay Zeka Modelimize gidecek olan veri;

 [[file:./images/screenshot-96.png]]

- tabiki bu sayılar direk bu şekilde yapay zeka modeline verilemez. sayıların normalize olması gerekir
** Normalizasyon

- Yapay Zeka algoritmalarına verilen verilerin 1 ile 0 arasına sıkıştırılması gerekir. Buna normalizasyon denir

- Basit bir normalizasyon tekniği olarak, sayıları maximum değerini bulup, tensörde bulunan her veriye bölmek verilebilir. Bu sayede tüm sayılar 1 ve 0 arasına sıkışır

  normalize olmamış veri: [108 104 102 103 65]

  en büyük sayı : 108

  normalize olmuş veri: [1, 0.96, 0.94, 0.95, 0.60]

*** Linear Scaling
TODO
*** Clipping
TODO
*** Log Scaling
TODO
*** Z-Score
TODO
*** Model Training

- *weight* : nöron içindeki veri. ilk anda rastgele bir sayıdır

- *bias*: bir nöral ağ parametresi

- *batch*: öğrenme sırasında sunulan veri

- *epoch*: eğitme sayısı

- *loss*: performans kriteridir ve mükemmel bir modelde sıfırdır

- *accuracy*: performans kriteridir ve mükemmel bir modelde 100% olması beklenir

- *hyperparameters*: yapay zeka modeli eğitilmeden önce yapılan ayarların tümüne denir

- *overfitting*: model datayı ezberlediğinde olur. bir modeli aşırı eğitirsek, çıkan model sadece eğitildiği datayı tanıyacaktır ve çok yüksek tahminler yapar. yeni bir veri geldiğinde kötü sonuç verecektir

- *underfit*: modeli yeterli data ile eğitmemişsek ya da nöral network'ün mimarisi, karmaşıklığı anlayamayacak kadar küçük olduğunda olur. kısaca underfit bir model yarıda kalmış bir modeldir.

- overfitting ile başa çıkmak için;

  + nöral network küçültülebilir ki veriyi tamamen ezberleyecek kadar geniş bir kapasiteye sahip olamasın.

  + daha fazla veri ile beslenebilir (en iyi çözümdür)

  + *data augmentation* diye bir teknik kullanılabilir. Bu teknik ile eldeki veri setini kullanarak yeni veriler elde edilebilir

  + *regularization* kullanılabilir. L1 ve L2 regularizasyon teknikleri kullanılabilir

  + *dropout*: eğitim sırasında, her *epoch*'da rastgele nöronlar arası bağlantıların rast gele koparılması tekniğine verilen isimdir
** train -> validate -> test

- genelde veri 3 parçaya bölünür;

  + %60 Training
  + %20 Validation
  + %20 Test

- overfit olan bir modelin validasyon verisiyle sınandığında oluşturduğu grafik. Bu tarz bir grafik oluşuyorsa bilin ki model overfit olmuş;

 [[file:./images/screenshot-98.png]]

- overfit olan modeli iyileştirmeye başladığımızda, her seferinde bir validasyon işleminden geçiririz. Bir süre sonra validasyonda başarı sağladığımızda hemen sevinmemek gerekir. çünkü modelimiz validasyon verisini de ezberlemiş olabilir ve validasyona göre de overfit olmuş olabilir. İşte bu yanılgıyı ortadan kaldırmak için bir de *test* datasını kullanırız. Test datasını, modelimizin validasyona göre overfit olup olmadığını anlamak için kullanırız

- test verisinde de başarılı olan bir model elde ettiğimiz zaman artık Yapay Zeka Modelimiz hazrı demektir ve MCU'da çalıştırılabilecek düzeye gelmiş demektir
** Converting the Model

- Yukarıda anlattığımız bütün train, validasyon ve test aşamalarını *normal* Tensorflow ile gerçekleştireceğiz.

- Modelimiz hazır hale geldikten sonra da Ram ve işlem gücü konusunda gelişmiş bilgisayarlardan daha zayıf olan Mikrodenetleyizimize (MCU) bu modeli çalıştırmak için *Tensorflow Lite* kullanırız

- Tensorflow Lite, modeli alır ve bir takım optimizasyonlar yapıp modelin daha küçük ve daha hızlı çalışmasını sağlar

- *Converting the Model*'dan kastımız da;

  Model --> Tensorflow Lite --> MCU uyumlu Model

- Modeli dönüştürme aşaması gayet hızlı ve kolay bir süreçtir
